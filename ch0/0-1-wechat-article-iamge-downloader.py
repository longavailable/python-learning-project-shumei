import requests
import re
import os
import time
from urllib.parse import urlparse, urljoin
from bs4 import BeautifulSoup


def wechat_order_downloader():
    headers = {
        'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 14_7_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148 MicroMessenger/8.0.15(0x18000f2e) NetType/WIFI Language/zh_CN',
        'Referer': 'https://mp.weixin.qq.com/'
    }

    article_url = input("è¯·è¾“å…¥å…¬ä¼—å·æ–‡ç« åœ°å€ï¼š").strip()

    if not article_url.startswith('http'):
        print("é”™è¯¯ï¼šè¯·è¾“å…¥æœ‰æ•ˆç½‘å€ï¼ˆä»¥http/httpså¼€å¤´ï¼‰")
        return

    try:
        # è·å–é¡µé¢å†…å®¹
        response = requests.get(article_url, headers=headers, timeout=15)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'lxml')

        # åˆ›å»ºæŒ‰æ—¥æœŸæ—¶é—´å‘½åçš„ä¸“å±ç›®å½•
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        save_dir = f"wechat_images_{timestamp}"
        os.makedirs(save_dir, exist_ok=True)

        # æ ¸å¿ƒè§£æé€»è¾‘
        img_counter = 1  # å›¾ç‰‡åºå·è®¡æ•°å™¨
        duplicate_check = set()  # é‡å¤å›¾ç‰‡æ ¡éªŒ

        for idx, img_tag in enumerate(soup.find_all('img'), 1):
            # ä¼˜å…ˆè·å–data-srcå±æ€§ï¼ˆå¾®ä¿¡æ‡’åŠ è½½ä¸“ç”¨ï¼‰
            img_url = img_tag.get('data-src') or img_tag.get('src')

            # å¤„ç†ç›¸å¯¹è·¯å¾„å’Œæ— æ•ˆURL
            if not img_url or 'http' not in img_url:
                continue
            full_url = urljoin(article_url, img_url)

            # è¿‡æ»¤éå¾®ä¿¡å›¾åºŠé“¾æ¥
            if 'mmbiz.qpic.cn' not in full_url:
                continue

            # è½¬æ¢é«˜æ¸…é“¾æ¥
            if '/640?' in full_url:
                hd_url = full_url.replace('/640?', '/0?')
            else:
                hd_url = full_url  # å·²ä¸ºé«˜æ¸…åœ°å€åˆ™ç›´æ¥ä½¿ç”¨

            # å»é‡æ ¡éªŒï¼ˆç²¾ç¡®åˆ°å›¾ç‰‡IDï¼‰
            unique_key = hd_url.split('/')[-2]
            if unique_key in duplicate_check:
                continue
            duplicate_check.add(unique_key)

            # ä¸‹è½½å¹¶ä¿å­˜
            try:
                response = requests.get(hd_url, headers=headers, timeout=10)
                if response.status_code == 200:
                    # æå–å›¾ç‰‡æ ¼å¼ï¼ˆä¼˜å…ˆURLå‚æ•°ï¼Œå…œåº•ç”¨headerï¼‰
                    content_type = response.headers.get('Content-Type', '')
                    fmt = 'jpg'  # å…œåº•é»˜è®¤æ ¼å¼
                    if 'wx_fmt=' in hd_url:
                        fmt = hd_url.split('wx_fmt=')[-1].split('&')[0]
                    elif 'image/' in content_type:
                        fmt = content_type.split('/')[-1]

                    # ç”Ÿæˆé¡ºåºç¼–å·æ–‡ä»¶å
                    filename = f"{img_counter:03d}.{fmt}"
                    save_path = os.path.join(save_dir, filename)

                    # ä¿å­˜æ–‡ä»¶
                    with open(save_path, 'wb') as f:
                        f.write(response.content)

                    print(f"âœ… ä¿å­˜ç¬¬ {img_counter} å¼ å›¾ç‰‡ â†’ {filename}")
                    img_counter += 1
                else:
                    print(f"âŒ ä¸‹è½½å¤±è´¥ï¼ˆçŠ¶æ€ç  {response.status_code}ï¼‰: {hd_url[:60]}...")

            except Exception as e:
                print(f"âš ï¸ å¼‚å¸¸ä¸‹è½½é¡¹ï¼š{str(e)[:50]}...")

            time.sleep(0.3)  # ç¤¼è²Œè®¿é—®é—´éš”

        print(f"\nğŸ‰ ä¸‹è½½å®Œæˆï¼å…±ä¿å­˜ {img_counter - 1} å¼ å›¾ç‰‡åˆ°ã€{save_dir}ã€‘ç›®å½•")

    except requests.RequestException as e:
        print(f"ç½‘ç»œè¯·æ±‚å¤±è´¥ï¼š{str(e)}")
    except Exception as e:
        print(f"ç¨‹åºå¼‚å¸¸ï¼š{str(e)}")

if __name__ == '__main__':
    wechat_order_downloader()
